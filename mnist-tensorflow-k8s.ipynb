{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a demo that demonstrates end to end workflow from training to serving of MNIST model with Tensorflow and Kubernetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# This is a placeholder for a Google-internal import.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Base path for exporting model\n",
    "# Set it to /home/jovyan/tf-serving-base/models to easily create a container and deploy\n",
    "export_path_base = \"/home/jovyan/tf-serving-base/models\"\n",
    "# Model Version\n",
    "model_version = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the devices available locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "[print(x.name) for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train a model based on mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training iterations\n",
    "training_iteration = 1000\n",
    "\n",
    "print('Training model...')\n",
    "sess = tf.InteractiveSession()\n",
    "serialized_tf_example = tf.placeholder(tf.string, name='tf_example')\n",
    "feature_configs = {'x': tf.FixedLenFeature(shape=[784], dtype=tf.float32),}\n",
    "tf_example = tf.parse_example(serialized_tf_example, feature_configs)\n",
    "x = tf.identity(tf_example['x'], name='x')  # use tf.identity() to assign name\n",
    "y_ = tf.placeholder('float', shape=[None, 10])\n",
    "w = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "y = tf.nn.softmax(tf.matmul(x, w) + b, name='y')\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "values, indices = tf.nn.top_k(y, 10)\n",
    "table = tf.contrib.lookup.index_to_string_table_from_tensor(\n",
    "    tf.constant([str(i) for i in range(10)]))\n",
    "prediction_classes = table.lookup(tf.to_int64(indices))\n",
    "for _ in range(training_iteration):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "print('training accuracy %g' % sess.run(\n",
    "    accuracy, feed_dict={x: mnist.test.images,\n",
    "                         y_: mnist.test.labels}))\n",
    "print('Done training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's export the model to a pre-defined directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "export_path = os.path.join(\n",
    "    tf.compat.as_bytes(export_path_base),\n",
    "    tf.compat.as_bytes(str(model_version)))\n",
    "print('Exporting trained model to', export_path)\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "# Build the signature_def_map.\n",
    "classification_inputs = tf.saved_model.utils.build_tensor_info(serialized_tf_example)\n",
    "classification_outputs_classes = tf.saved_model.utils.build_tensor_info(prediction_classes)\n",
    "classification_outputs_scores = tf.saved_model.utils.build_tensor_info(values)\n",
    "\n",
    "classification_signature = (\n",
    "      tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={\n",
    "              tf.saved_model.signature_constants.CLASSIFY_INPUTS:\n",
    "                  classification_inputs\n",
    "          },\n",
    "          outputs={\n",
    "              tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES:\n",
    "                  classification_outputs_classes,\n",
    "              tf.saved_model.signature_constants.CLASSIFY_OUTPUT_SCORES:\n",
    "                  classification_outputs_scores\n",
    "          },\n",
    "          method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME))\n",
    "\n",
    "tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
    "tensor_info_y = tf.saved_model.utils.build_tensor_info(y)\n",
    "\n",
    "prediction_signature = (\n",
    "      tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={'images': tensor_info_x},\n",
    "          outputs={'scores': tensor_info_y},\n",
    "          method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "builder.add_meta_graph_and_variables(\n",
    "      sess, [tf.saved_model.tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "          'predict_images':\n",
    "              prediction_signature,\n",
    "          tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "              classification_signature,\n",
    "      },\n",
    "      legacy_init_op=legacy_init_op)\n",
    "\n",
    "builder.save()\n",
    "\n",
    "print('Done exporting!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build a container with the model just generated.\n",
    "### Open Terminal and run \"cd tf-serving-base && ./build_and_export.sh 'gcr.io project name'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets start a Kubernetes Deployment that runs Tensorflow Serving with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import yaml\n",
    "import time\n",
    "\n",
    "from kubernetes import client, config\n",
    "\n",
    "config.load_incluster_config()\n",
    "\n",
    "with open(\"/home/jovyan/tf-serving-base/deployment.yaml\") as f:\n",
    "    dep = yaml.load(f)\n",
    "    # Specify the newly built image.\n",
    "    dep['spec']['template']['spec']['containers'][0]['image'] = \"gcr.io/vishnuk-cloud/tf-model-server:latest\"\n",
    "    k8s_beta = client.ExtensionsV1beta1Api()\n",
    "    try:\n",
    "        resp = k8s_beta.delete_namespaced_deployment(body={}, namespace=\"jupyterhub\", name=dep['metadata']['name'])\n",
    "        time.sleep(10)\n",
    "    except:\n",
    "        pass\n",
    "    resp = k8s_beta.create_namespaced_deployment(body=dep, namespace=\"jupyterhub\")\n",
    "    print(\"Deployment created. status='%s'\" % str(resp.status))\n",
    "\n",
    "with open(\"/home/jovyan/tf-serving-base/service.yaml\") as f:\n",
    "    dep = yaml.load(f)\n",
    "    v1 = client.CoreV1Api()\n",
    "    v1.delete_namespaced_service(namespace=\"jupyterhub\", name=dep['metadata']['name'])\n",
    "    resp = v1.create_namespaced_service(body=dep, namespace=\"jupyterhub\")\n",
    "    print(\"Service created. status='%s'\" % str(resp.status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
