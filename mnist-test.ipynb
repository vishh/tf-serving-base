{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import threading\n",
    "\n",
    "\n",
    "from grpc.beta import implementations\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "server = \"tf-service:9000\"\n",
    "\n",
    "class _ResultCounter(object):\n",
    "  \"\"\"Counter for the prediction results.\"\"\"\n",
    "\n",
    "  def __init__(self, num_tests, concurrency):\n",
    "    self._num_tests = 100\n",
    "    self._concurrency = 1\n",
    "    self._error = 0\n",
    "    self._done = 0\n",
    "    self._active = 0\n",
    "    self._condition = threading.Condition()\n",
    "    self._workdir = \"/tmp\"\n",
    "\n",
    "  def inc_error(self):\n",
    "    with self._condition:\n",
    "      self._error += 1\n",
    "\n",
    "  def inc_done(self):\n",
    "    with self._condition:\n",
    "      self._done += 1\n",
    "      self._condition.notify()\n",
    "\n",
    "  def dec_active(self):\n",
    "    with self._condition:\n",
    "      self._active -= 1\n",
    "      self._condition.notify()\n",
    "\n",
    "  def get_error_rate(self):\n",
    "    with self._condition:\n",
    "      while self._done != self._num_tests:\n",
    "        self._condition.wait()\n",
    "      return self._error / float(self._num_tests)\n",
    "\n",
    "  def throttle(self):\n",
    "    with self._condition:\n",
    "      while self._active == self._concurrency:\n",
    "        self._condition.wait()\n",
    "      self._active += 1\n",
    "\n",
    "\n",
    "def _create_rpc_callback(label, result_counter):\n",
    "  \"\"\"Creates RPC callback function.\n",
    "  Args:\n",
    "    label: The correct label for the predicted example.\n",
    "    result_counter: Counter for the prediction result.\n",
    "  Returns:\n",
    "    The callback function.\n",
    "  \"\"\"\n",
    "  def _callback(result_future):\n",
    "    \"\"\"Callback function.\n",
    "    Calculates the statistics for the prediction result.\n",
    "    Args:\n",
    "      result_future: Result future of the RPC.\n",
    "    \"\"\"\n",
    "    exception = result_future.exception()\n",
    "    if exception:\n",
    "      result_counter.inc_error()\n",
    "      print(exception)\n",
    "    else:\n",
    "      sys.stdout.write('.')\n",
    "      sys.stdout.flush()\n",
    "      response = numpy.array(\n",
    "          result_future.result().outputs['scores'].float_val)\n",
    "      prediction = numpy.argmax(response)\n",
    "      if label.argmax() != prediction:\n",
    "        result_counter.inc_error()\n",
    "    result_counter.inc_done()\n",
    "    result_counter.dec_active()\n",
    "  return _callback\n",
    "\n",
    "\n",
    "def do_inference(hostport, work_dir, concurrency, num_tests):\n",
    "  \"\"\"Tests PredictionService with concurrent requests.\n",
    "  Args:\n",
    "    hostport: Host:port address of the PredictionService.\n",
    "    work_dir: The full path of working directory for test data set.\n",
    "    concurrency: Maximum number of concurrent requests.\n",
    "    num_tests: Number of test images to use.\n",
    "  Returns:\n",
    "    The classification error rate.\n",
    "  Raises:\n",
    "    IOError: An error occurred processing test data set.\n",
    "  \"\"\"\n",
    "  test_data_set = mnist.test\n",
    "  host, port = hostport.split(':')\n",
    "  channel = implementations.insecure_channel(host, int(port))\n",
    "  stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n",
    "  result_counter = _ResultCounter(num_tests, concurrency)\n",
    "  for _ in range(num_tests):\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = 'default'\n",
    "    request.model_spec.signature_name = 'predict_images'\n",
    "    image, label = test_data_set.next_batch(1)\n",
    "    request.inputs['images'].CopyFrom(\n",
    "        tf.contrib.util.make_tensor_proto(image[0], shape=[1, image[0].size]))\n",
    "    result_counter.throttle()\n",
    "    result_future = stub.Predict.future(request, 5.0)  # 5 seconds\n",
    "    result_future.add_done_callback(\n",
    "        _create_rpc_callback(label[0], result_counter))\n",
    "  return result_counter.get_error_rate()\n",
    "\n",
    "error_rate = do_inference(server, \"/tmp\", 1, 100)\n",
    "print('\\nInference error rate: %s%%' % (error_rate * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
